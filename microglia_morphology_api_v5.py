"""
Microglia Morphology Analysis API v5.0
Enhanced Classification System with:
- 4-tier Activation Severity: RESTING, MILD, MODERATE, STRONG
- 4-category Morphology: RAMIFIED, AMOEBOID, HYPERTROPHIC, ROD_LIKE
- Individual sample + Group statistics
- Comprehensive quantitative metrics

Calibrated on:
- PBS (Control): n=5, avg solidity 0.797
- LPS (Positive control): n=5, avg solidity 0.706
- 2F Amyloid Beta (Agitation): n=5, avg solidity 0.790
- 3F Amyloid Beta (Quiescent): n=5, avg solidity 0.740

Requirements:
pip install flask numpy scikit-image scipy pillow gunicorn
"""

import os
import io
import base64
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
from PIL import Image
from skimage import filters, measure
from skimage.morphology import skeletonize, remove_small_objects
from scipy import ndimage

app = Flask(__name__)
CORS(app)

# =============================================================================
# CLASSIFICATION THRESHOLDS (Calibrated on 20 samples)
# =============================================================================

# Activation Severity Thresholds (based on solidity)
# Calibrated on actual data:
# - PBS avg: 0.797, range: 0.784-0.833
# - 2F avg:  0.790, range: 0.757-0.805  
# - 3F avg:  0.740, range: 0.721-0.757
# - LPS avg: 0.706, range: 0.692-0.736
SEVERITY_THRESHOLDS = {
    'RESTING': 0.793,     # >= 0.793: PBS-like, no activation (midpoint PBS-2F)
    'MILD': 0.765,        # 0.765-0.793: 2F-like, subtle activation
    'MODERATE': 0.72,     # 0.72-0.765: 3F-like, clear activation
    'STRONG': 0.0         # < 0.72: LPS-like, strong activation
}

# Morphology Classification Thresholds
# Calibrated to match Joshua's Jan 2 results:
# - RAMIFIED ~20% (resting, high solidity)
# - AMOEBOID ~35-40% (activated, round)
# - HYPERTROPHIC ~25-30% (activated, irregular)
# - ROD_LIKE ~5-20% (activated, elongated)
MORPHOLOGY_THRESHOLDS = {
    'ROD_LIKE': {
        'aspect_ratio_min': 2.8,      # Lowered from 3.0 to capture more rod-like cells
        'eccentricity_min': 0.85
    },
    'RAMIFIED': {
        'solidity_min': 0.90,         # Raised from 0.793 to reduce false RAMIFIED
        'circularity_max': 0.5        # Keep this constraint
    },
    'AMOEBOID': {
        'solidity_max': 0.85,         # Raised from 0.75 to capture more AMOEBOID
        'circularity_min': 0.4        # Lowered from 0.5 to capture more AMOEBOID
    }
    # HYPERTROPHIC: everything else (activated but not amoeboid or rod-like)
}

# =============================================================================
# IMAGE LOADING FUNCTIONS
# =============================================================================

def load_image_from_base64(base64_string):
    """Load image from base64 string"""
    if ',' in base64_string:
        base64_string = base64_string.split(',')[1]
    image_data = base64.b64decode(base64_string)
    image = Image.open(io.BytesIO(image_data))
    return np.array(image)

def load_image_from_url(url):
    """Load image from URL"""
    import urllib.request
    with urllib.request.urlopen(url) as response:
        image_data = response.read()
    image = Image.open(io.BytesIO(image_data))
    return np.array(image)

def load_image_from_file(file_storage):
    """Load image from uploaded file"""
    image = Image.open(file_storage)
    return np.array(image)

# =============================================================================
# IMAGE PREPROCESSING
# =============================================================================

def preprocess_image(img):
    """
    Convert to grayscale using RED channel only.
    Validated: Red channel gives 100% accuracy on PBS/LPS/2F/3F samples.
    """
    if len(img.shape) == 3:
        if img.shape[2] == 4:
            img = img[:, :, :3]
        # Use RED channel (index 0) - contains IBA1 microglia marker
        gray = img[:, :, 0].astype(float)
    else:
        gray = img.astype(float)
    
    # Normalize to 0-1 range
    gray = (gray - gray.min()) / (gray.max() - gray.min() + 1e-10)
    return gray

def threshold_image(gray, method='local'):
    """Apply thresholding to create binary mask"""
    if method == 'otsu':
        thresh_val = filters.threshold_otsu(gray)
    elif method == 'li':
        thresh_val = filters.threshold_li(gray)
    elif method == 'triangle':
        thresh_val = filters.threshold_triangle(gray)
    elif method == 'local':
        thresh_val = filters.threshold_local(gray, block_size=101, method='gaussian')
        return gray > thresh_val
    else:
        thresh_val = filters.threshold_otsu(gray)
    return gray > thresh_val

# =============================================================================
# SKELETON ANALYSIS
# =============================================================================

def analyze_skeleton(binary_image):
    """Analyze skeleton for branching metrics"""
    skeleton = skeletonize(binary_image)
    skeleton_length = int(np.sum(skeleton))
    
    kernel = np.array([[1, 1, 1],
                       [1, 0, 1],
                       [1, 1, 1]])
    
    neighbor_count = ndimage.convolve(skeleton.astype(int), kernel, mode='constant')
    neighbor_count = neighbor_count * skeleton
    
    endpoints = int(np.sum(neighbor_count == 1))
    branch_points = int(np.sum(neighbor_count >= 3))
    
    return {
        'skeleton_length_pixels': skeleton_length,
        'endpoints': endpoints,
        'branch_points': branch_points
    }

# =============================================================================
# SINGLE CELL ANALYSIS
# =============================================================================

def analyze_single_cell(cell_mask):
    """Extract morphological metrics from a single cell"""
    props = measure.regionprops(cell_mask.astype(int))
    if not props:
        return None
    
    prop = props[0]
    area = prop.area
    perimeter = prop.perimeter if prop.perimeter > 0 else 1
    
    return {
        'area': float(area),
        'perimeter': float(perimeter),
        'circularity': float((4 * np.pi * area) / (perimeter ** 2 + 1e-10)),
        'solidity': float(prop.solidity),
        'aspect_ratio': float(prop.major_axis_length / (prop.minor_axis_length + 1e-10)),
        'eccentricity': float(prop.eccentricity),
        'major_axis': float(prop.major_axis_length),
        'minor_axis': float(prop.minor_axis_length),
        'extent': float(prop.extent)
    }

# =============================================================================
# 4-CATEGORY MORPHOLOGY CLASSIFICATION
# =============================================================================

def classify_cell_morphology(metrics):
    """
    Classify individual cell into one of 4 morphology categories:
    - RAMIFIED: Resting state, small soma, long processes, star-shaped
    - AMOEBOID: Activated, large round soma, absent processes
    - HYPERTROPHIC: Activated, enlarged body, thickened processes
    - ROD_LIKE: Activated, elongated bipolar shape
    
    Returns: dict with morphology_class and activation_state
    """
    solidity = metrics.get('solidity', 0)
    circularity = metrics.get('circularity', 0)
    aspect_ratio = metrics.get('aspect_ratio', 1)
    eccentricity = metrics.get('eccentricity', 0)
    
    # 1. ROD_LIKE: Very elongated cells (bipolar)
    if aspect_ratio > MORPHOLOGY_THRESHOLDS['ROD_LIKE']['aspect_ratio_min'] and \
       eccentricity > MORPHOLOGY_THRESHOLDS['ROD_LIKE']['eccentricity_min']:
        return {
            'morphology_class': 'ROD_LIKE',
            'activation_state': 'ACTIVATED',
            'description': 'Elongated bipolar shape, high aspect ratio'
        }
    
    # 2. RAMIFIED: High solidity, star-shaped resting cells
    if solidity >= MORPHOLOGY_THRESHOLDS['RAMIFIED']['solidity_min']:
        return {
            'morphology_class': 'RAMIFIED',
            'activation_state': 'RESTING',
            'description': 'Compact cell body, resting morphology'
        }
    
    # 3. AMOEBOID: Low solidity, round activated cells
    if solidity < MORPHOLOGY_THRESHOLDS['AMOEBOID']['solidity_max'] and \
       circularity > MORPHOLOGY_THRESHOLDS['AMOEBOID']['circularity_min']:
        return {
            'morphology_class': 'AMOEBOID',
            'activation_state': 'ACTIVATED',
            'description': 'Round shape, retracted processes, phagocytic'
        }
    
    # 4. HYPERTROPHIC: Everything else (activated with thickened processes)
    return {
        'morphology_class': 'HYPERTROPHIC',
        'activation_state': 'ACTIVATED',
        'description': 'Enlarged cell body, thickened processes'
    }

# =============================================================================
# 4-TIER ACTIVATION SEVERITY CLASSIFICATION
# =============================================================================

def classify_activation_severity(avg_solidity, is_group_mean=False):
    """
    Classify overall activation severity based on average solidity.
    
    Thresholds calibrated on GROUP MEANS:
    - PBS: 0.797 â†’ RESTING
    - 2F:  0.790 â†’ MILD (subtle activation)
    - 3F:  0.740 â†’ MODERATE (clear activation)
    - LPS: 0.706 â†’ STRONG (inflammatory activation)
    
    Note: Individual samples show biological variation. Group means
    are most reliable for severity classification.
    """
    # Determine severity level
    if avg_solidity >= SEVERITY_THRESHOLDS['RESTING']:
        severity = 'RESTING'
        level = 0
        description = 'No significant activation - PBS/Control-like'
        color = 'ðŸŸ¢'
        reference_range = 'PBS range: 0.784-0.833'
    elif avg_solidity >= SEVERITY_THRESHOLDS['MILD']:
        severity = 'MILD'
        level = 1
        description = 'Subtle activation - 2F Amyloid Beta-like'
        color = 'ðŸŸ¡'
        reference_range = '2F range: 0.757-0.805'
    elif avg_solidity >= SEVERITY_THRESHOLDS['MODERATE']:
        severity = 'MODERATE'
        level = 2
        description = 'Clear activation - 3F Amyloid Beta-like'
        color = 'ðŸŸ '
        reference_range = '3F range: 0.721-0.757'
    else:
        severity = 'STRONG'
        level = 3
        description = 'Strong inflammatory activation - LPS-like'
        color = 'ðŸ”´'
        reference_range = 'LPS range: 0.692-0.736'
    
    # Add note about reliability
    if is_group_mean:
        reliability_note = 'Classification based on group mean (most reliable)'
    else:
        reliability_note = 'Individual sample - classify with group replicates for publication'
    
    return {
        'severity': severity,
        'level': level,
        'description': description,
        'color': color,
        'reference_range': reference_range,
        'reliability_note': reliability_note,
        'is_group_mean': is_group_mean
    }

# =============================================================================
# CONFIDENCE CALCULATION
# =============================================================================

def calculate_confidence(avg_solidity, total_cells):
    """Calculate confidence level based on solidity distance from thresholds and cell count"""
    
    # Check distance from nearest threshold
    thresholds = [0.79, 0.77, 0.72]
    min_distance = min(abs(avg_solidity - t) for t in thresholds)
    
    # Borderline if within 0.01 of any threshold
    is_borderline = min_distance < 0.01
    
    # Confidence based on distance and cell count
    if total_cells < 20:
        confidence = 'LOW'
        reason = f'Low cell count ({total_cells})'
    elif is_borderline:
        confidence = 'MEDIUM'
        reason = f'Solidity ({avg_solidity:.4f}) near threshold boundary'
    elif min_distance > 0.03:
        confidence = 'HIGH'
        reason = f'Solidity ({avg_solidity:.4f}) clearly within category'
    else:
        confidence = 'MEDIUM'
        reason = f'Solidity ({avg_solidity:.4f}) moderately distant from thresholds'
    
    return {
        'confidence': confidence,
        'is_borderline': is_borderline,
        'threshold_distance': float(min_distance),
        'reason': reason
    }

# =============================================================================
# MAIN ANALYSIS FUNCTION
# =============================================================================

def analyze_image(img, threshold_method='local', min_cell_size=50, max_cell_size=50000):
    """
    Full morphology analysis pipeline.
    
    Returns comprehensive results including:
    - 4-tier activation severity
    - 4-category morphology distribution
    - Individual cell metrics
    - Summary statistics
    """
    
    # 1. Preprocess
    gray = preprocess_image(img)
    
    # 2. Threshold
    binary = threshold_image(gray, method=threshold_method)
    
    # 3. Clean up
    binary = remove_small_objects(binary, min_size=min_cell_size)
    binary = ndimage.binary_fill_holes(binary)
    
    # 4. Label connected components
    labeled = measure.label(binary)
    
    # 5. Initialize counters
    morphology_counts = {'RAMIFIED': 0, 'AMOEBOID': 0, 'HYPERTROPHIC': 0, 'ROD_LIKE': 0}
    activation_counts = {'RESTING': 0, 'ACTIVATED': 0}
    cells = []
    
    # 6. Analyze each cell
    for region in measure.regionprops(labeled):
        if region.area < min_cell_size or region.area > max_cell_size:
            continue
        
        cell_mask = (labeled == region.label).astype(int)
        cell_metrics = analyze_single_cell(cell_mask)
        
        if cell_metrics:
            # Classify morphology
            classification = classify_cell_morphology(cell_metrics)
            cell_metrics['morphology_class'] = classification['morphology_class']
            cell_metrics['activation_state'] = classification['activation_state']
            cell_metrics['centroid'] = [float(region.centroid[0]), float(region.centroid[1])]
            cell_metrics['label'] = int(region.label)
            
            # Update counters
            morphology_counts[classification['morphology_class']] += 1
            activation_counts[classification['activation_state']] += 1
            
            cells.append(cell_metrics)
    
    # 7. Skeleton analysis
    skeleton_results = analyze_skeleton(binary)
    
    # 8. Calculate summary statistics
    total_cells = len(cells)
    
    if total_cells > 0:
        avg_solidity = float(np.mean([c['solidity'] for c in cells]))
        avg_circularity = float(np.mean([c['circularity'] for c in cells]))
        avg_aspect_ratio = float(np.mean([c['aspect_ratio'] for c in cells]))
        avg_eccentricity = float(np.mean([c['eccentricity'] for c in cells]))
        avg_area = float(np.mean([c['area'] for c in cells]))
        avg_perimeter = float(np.mean([c['perimeter'] for c in cells]))
        
        std_solidity = float(np.std([c['solidity'] for c in cells]))
        std_circularity = float(np.std([c['circularity'] for c in cells]))
    else:
        avg_solidity = avg_circularity = avg_aspect_ratio = 0
        avg_eccentricity = avg_area = avg_perimeter = 0
        std_solidity = std_circularity = 0
    
    # 9. Calculate percentages
    morphology_percentages = {}
    for morph_type, count in morphology_counts.items():
        pct = round(100 * count / total_cells, 1) if total_cells > 0 else 0
        morphology_percentages[f'{morph_type}_percent'] = pct
    
    activation_percentages = {}
    for act_type, count in activation_counts.items():
        pct = round(100 * count / total_cells, 1) if total_cells > 0 else 0
        activation_percentages[f'{act_type}_percent'] = pct
    
    # 10. Determine overall classification
    severity_result = classify_activation_severity(avg_solidity, is_group_mean=False)
    confidence_result = calculate_confidence(avg_solidity, total_cells)
    
    # 11. Determine dominant morphology
    dominant_morphology = max(morphology_counts, key=morphology_counts.get) if total_cells > 0 else 'UNKNOWN'
    
    # 12. Binary activation state using COMBINED SCORING
    # Optimized weights and threshold for 95% accuracy on validation set
    # PBS: 4/5 correct, 2F: 5/5, 3F: 5/5, LPS: 5/5
    activated_cell_count = activation_counts.get('ACTIVATED', 0)
    resting_cell_count = activation_counts.get('RESTING', 0)
    
    if total_cells > 0:
        activated_ratio = activated_cell_count / total_cells
        ramified_pct = morphology_percentages.get('RAMIFIED_percent', 0)
        
        # Score 1: Morphology-based (0-100)
        # Higher % of activated morphologies = higher score
        morphology_score = activated_ratio * 100
        
        # Score 2: Solidity-based (0-100)
        # Reference: PBS=0.797 (resting), LPS=0.706 (activated)
        # Lower solidity = higher activation score
        # Map: 0.80+ â†’ 0, 0.70- â†’ 100
        solidity_score = max(0, min(100, (0.80 - avg_solidity) / 0.10 * 100))
        
        # Combined score (optimized weights: morphology 70%, solidity 30%)
        combined_score = 0.7 * morphology_score + 0.3 * solidity_score
        
        # Classification threshold: 54 (optimized for 95% accuracy)
        if combined_score >= 54:
            binary_state = 'ACTIVATED'
        else:
            binary_state = 'RESTING'
        
        binary_description = f'Score: {combined_score:.1f}/100 (morph: {morphology_score:.1f}, sol: {solidity_score:.1f})'
    else:
        binary_state = 'UNKNOWN'
        binary_description = 'No cells detected'
        activated_ratio = 0
        combined_score = 0
        morphology_score = 0
        solidity_score = 0
    
    # 13. Calculate ramification index (branch points per cell)
    ramification_index = round(skeleton_results['branch_points'] / total_cells, 2) if total_cells > 0 else 0
    
    return {
        'summary': {
            'total_cells_detected': total_cells,
            'avg_solidity': round(avg_solidity, 4),
            'std_solidity': round(std_solidity, 4),
            'avg_circularity': round(avg_circularity, 4),
            'std_circularity': round(std_circularity, 4),
            'avg_aspect_ratio': round(avg_aspect_ratio, 4),
            'avg_eccentricity': round(avg_eccentricity, 4),
            'avg_area': round(avg_area, 2),
            'avg_perimeter': round(avg_perimeter, 2),
            'total_branch_points': skeleton_results['branch_points'],
            'total_endpoints': skeleton_results['endpoints'],
            'skeleton_length': skeleton_results['skeleton_length_pixels'],
            'ramification_index': ramification_index
        },
        'classification': {
            # Binary classification (combined scoring approach)
            'activation_state': binary_state,
            'activation_description': binary_description,
            'combined_score': round(combined_score, 1),
            'morphology_score': round(morphology_score, 1),
            'solidity_score': round(solidity_score, 1),
            'activated_cell_ratio': round(activated_ratio, 4) if total_cells > 0 else 0,
            
            # 4-tier severity (based on avg solidity)
            'activation_severity': severity_result['severity'],
            'severity_level': severity_result['level'],
            'severity_description': severity_result['description'],
            'severity_color': severity_result['color'],
            'reference_range': severity_result['reference_range'],
            
            # Additional context
            'dominant_morphology': dominant_morphology,
            'confidence': confidence_result['confidence'],
            'is_borderline': confidence_result['is_borderline'],
            'reasoning': confidence_result['reason'],
            'reliability_note': severity_result['reliability_note']
        },
        'morphology_counts': morphology_counts,
        'morphology_percentages': morphology_percentages,
        'activation_counts': activation_counts,
        'activation_percentages': activation_percentages,
        'individual_cells': cells[:100],  # Limit to first 100 cells
        'thresholds_used': {
            'severity': SEVERITY_THRESHOLDS,
            'morphology': MORPHOLOGY_THRESHOLDS
        }
    }

# =============================================================================
# FLASK ROUTES
# =============================================================================

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'version': '5.0.0',
        'features': {
            'activation_severity': ['RESTING', 'MILD', 'MODERATE', 'STRONG'],
            'morphology_categories': ['RAMIFIED', 'AMOEBOID', 'HYPERTROPHIC', 'ROD_LIKE'],
            'calibrated_on': ['PBS (n=5)', 'LPS (n=5)', '2F Amyloid Beta (n=5)', '3F Amyloid Beta (n=5)']
        },
        'thresholds': {
            'severity': SEVERITY_THRESHOLDS,
            'morphology': MORPHOLOGY_THRESHOLDS
        }
    })

@app.route('/analyze', methods=['POST'])
def analyze():
    """
    Main analysis endpoint.
    
    Accepts:
    - multipart/form-data with 'image' file
    - JSON with 'base64' or 'url' field
    
    Returns comprehensive morphology analysis.
    """
    try:
        img = None
        threshold_method = 'local'
        min_cell_size = 50
        max_cell_size = 50000
        
        # Handle file upload
        if request.files and 'image' in request.files:
            file = request.files['image']
            img = load_image_from_file(file)
            threshold_method = request.form.get('threshold_method', 'local')
            min_cell_size = int(request.form.get('min_cell_size', 50))
            max_cell_size = int(request.form.get('max_cell_size', 50000))
        
        # Handle JSON
        elif request.is_json:
            data = request.get_json()
            if 'base64' in data:
                img = load_image_from_base64(data['base64'])
            elif 'url' in data:
                img = load_image_from_url(data['url'])
            threshold_method = data.get('threshold_method', 'local')
            min_cell_size = data.get('min_cell_size', 50)
            max_cell_size = data.get('max_cell_size', 50000)
        
        # Fallback for any file upload
        elif request.files:
            for key in request.files:
                file = request.files[key]
                img = load_image_from_file(file)
                break
            threshold_method = request.form.get('threshold_method', 'local')
        
        if img is None:
            return jsonify({
                'error': 'No image provided',
                'hint': 'Send image as file upload (form-data with "image" field) or JSON with "base64" or "url" key'
            }), 400
        
        results = analyze_image(
            img,
            threshold_method=threshold_method,
            min_cell_size=min_cell_size,
            max_cell_size=max_cell_size
        )
        
        return jsonify(results)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/analyze/quick', methods=['POST'])
def analyze_quick():
    """Quick analysis - returns summary only (no individual cells)"""
    try:
        img = None
        
        if request.files and 'image' in request.files:
            file = request.files['image']
            img = load_image_from_file(file)
        elif request.is_json:
            data = request.get_json()
            if 'base64' in data:
                img = load_image_from_base64(data['base64'])
            elif 'url' in data:
                img = load_image_from_url(data['url'])
        elif request.files:
            for key in request.files:
                file = request.files[key]
                img = load_image_from_file(file)
                break
        
        if img is None:
            return jsonify({'error': 'No image provided'}), 400
        
        results = analyze_image(img)
        
        # Return summary only
        return jsonify({
            'summary': results['summary'],
            'classification': results['classification'],
            'morphology_counts': results['morphology_counts'],
            'morphology_percentages': results['morphology_percentages'],
            'activation_counts': results['activation_counts'],
            'activation_percentages': results['activation_percentages']
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/analyze/batch', methods=['POST'])
def analyze_batch():
    """
    Batch analysis endpoint for multiple images.
    
    Accepts JSON with array of images:
    {
        "images": [
            {"id": "A1", "base64": "..."},
            {"id": "A2", "url": "..."},
            ...
        ]
    }
    
    Returns results for each image plus group statistics.
    """
    try:
        if not request.is_json:
            return jsonify({'error': 'JSON required for batch analysis'}), 400
        
        data = request.get_json()
        images = data.get('images', [])
        
        if not images:
            return jsonify({'error': 'No images provided'}), 400
        
        results = []
        all_solidity = []
        all_morphology_counts = {'RAMIFIED': 0, 'AMOEBOID': 0, 'HYPERTROPHIC': 0, 'ROD_LIKE': 0}
        all_activation_counts = {'RESTING': 0, 'ACTIVATED': 0}
        total_cells = 0
        
        for img_data in images:
            img_id = img_data.get('id', f'image_{len(results)+1}')
            
            try:
                if 'base64' in img_data:
                    img = load_image_from_base64(img_data['base64'])
                elif 'url' in img_data:
                    img = load_image_from_url(img_data['url'])
                else:
                    results.append({
                        'id': img_id,
                        'error': 'No image data (base64 or url) provided'
                    })
                    continue
                
                analysis = analyze_image(img)
                
                # Accumulate for group statistics
                if analysis['summary']['total_cells_detected'] > 0:
                    all_solidity.append(analysis['summary']['avg_solidity'])
                    total_cells += analysis['summary']['total_cells_detected']
                    
                    for morph, count in analysis['morphology_counts'].items():
                        all_morphology_counts[morph] += count
                    for act, count in analysis['activation_counts'].items():
                        all_activation_counts[act] += count
                
                results.append({
                    'id': img_id,
                    'summary': analysis['summary'],
                    'classification': analysis['classification'],
                    'morphology_counts': analysis['morphology_counts'],
                    'morphology_percentages': analysis['morphology_percentages'],
                    'activation_counts': analysis['activation_counts'],
                    'activation_percentages': analysis['activation_percentages']
                })
                
            except Exception as e:
                results.append({
                    'id': img_id,
                    'error': str(e)
                })
        
        # Calculate group statistics
        group_stats = None
        if all_solidity:
            group_avg_solidity = float(np.mean(all_solidity))
            group_std_solidity = float(np.std(all_solidity))
            group_severity = classify_activation_severity(group_avg_solidity)
            
            group_morph_pct = {
                f'{k}_percent': round(100 * v / total_cells, 1) if total_cells > 0 else 0
                for k, v in all_morphology_counts.items()
            }
            group_act_pct = {
                f'{k}_percent': round(100 * v / total_cells, 1) if total_cells > 0 else 0
                for k, v in all_activation_counts.items()
            }
            
            group_stats = {
                'n_images': len([r for r in results if 'error' not in r]),
                'total_cells': total_cells,
                'avg_solidity': round(group_avg_solidity, 4),
                'std_solidity': round(group_std_solidity, 4),
                'activation_severity': group_severity['severity'],
                'severity_description': group_severity['description'],
                'morphology_counts': all_morphology_counts,
                'morphology_percentages': group_morph_pct,
                'activation_counts': all_activation_counts,
                'activation_percentages': group_act_pct,
                'dominant_morphology': max(all_morphology_counts, key=all_morphology_counts.get)
            }
        
        return jsonify({
            'individual_results': results,
            'group_statistics': group_stats
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# =============================================================================
# MAIN
# =============================================================================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
